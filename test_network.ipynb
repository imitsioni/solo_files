{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (h_lp): Linear(in_features=60, out_features=100, bias=False)\n",
      "  (h_lc): Linear(in_features=60, out_features=100, bias=False)\n",
      "  (h_c): Linear(in_features=60, out_features=100, bias=False)\n",
      "  (h_f): Linear(in_features=30, out_features=100, bias=False)\n",
      "  (h_l): Linear(in_features=50, out_features=100, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[-0.1144, -0.0913,  0.0134,  ..., -0.0179,  0.0366, -0.0800],\n",
      "        [ 0.0310,  0.1268,  0.0688,  ...,  0.1161, -0.0535, -0.0967],\n",
      "        [-0.0192, -0.1107,  0.0344,  ...,  0.0892, -0.0781,  0.1085],\n",
      "        ...,\n",
      "        [-0.0049, -0.0920, -0.0387,  ...,  0.0410, -0.0537, -0.0271],\n",
      "        [ 0.0057,  0.0516,  0.0181,  ...,  0.0810,  0.0922,  0.0146],\n",
      "        [ 0.0453,  0.0929, -0.0525,  ..., -0.0208,  0.0633,  0.0354]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0561, -0.0538,  0.1261,  ..., -0.0370, -0.0854,  0.0028],\n",
      "        [-0.0828,  0.0712, -0.1020,  ..., -0.1130,  0.0337, -0.0797],\n",
      "        [-0.1250,  0.0315,  0.0308,  ..., -0.0224, -0.0763, -0.0142],\n",
      "        ...,\n",
      "        [-0.0140,  0.0625, -0.0338,  ..., -0.0219, -0.1099, -0.0459],\n",
      "        [ 0.0354, -0.0214,  0.0976,  ..., -0.1148,  0.1217, -0.0813],\n",
      "        [-0.0272, -0.0360, -0.0982,  ...,  0.0774,  0.0715,  0.1021]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0644, -0.0284, -0.0823,  ...,  0.0403, -0.0427,  0.0283],\n",
      "        [-0.0735,  0.0174, -0.0461,  ..., -0.0325,  0.0700, -0.0738],\n",
      "        [-0.0262, -0.0570,  0.0245,  ...,  0.1084, -0.0632,  0.0391],\n",
      "        ...,\n",
      "        [-0.0036, -0.0663, -0.0089,  ...,  0.0149,  0.0734, -0.0963],\n",
      "        [-0.0829, -0.0302,  0.1187,  ..., -0.0959,  0.0081,  0.0124],\n",
      "        [-0.0830,  0.0619, -0.1200,  ...,  0.0103, -0.1093, -0.0240]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1146, -0.0032, -0.0373,  ...,  0.1486,  0.0769, -0.0668],\n",
      "        [ 0.0772,  0.1796,  0.0351,  ..., -0.1353, -0.1133, -0.0580],\n",
      "        [ 0.1741, -0.0608, -0.0517,  ..., -0.0317, -0.0372, -0.0533],\n",
      "        ...,\n",
      "        [ 0.1247, -0.0116,  0.1777,  ..., -0.0361,  0.1339,  0.0686],\n",
      "        [-0.0251, -0.1359,  0.0295,  ...,  0.0405, -0.0230,  0.1334],\n",
      "        [ 0.0277,  0.0573,  0.0272,  ...,  0.1589, -0.1272,  0.0727]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0438, -0.1251, -0.0671,  ..., -0.0309,  0.1411,  0.0143],\n",
      "        [-0.1365, -0.0039,  0.0844,  ...,  0.0087, -0.1157, -0.0132],\n",
      "        [ 0.0708,  0.0619,  0.0610,  ...,  0.1168,  0.0719, -0.1239],\n",
      "        ...,\n",
      "        [ 0.1001,  0.0328, -0.1253,  ...,  0.0446,  0.0296,  0.0007],\n",
      "        [ 0.1091, -0.0128, -0.1354,  ..., -0.0470,  0.0024, -0.0771],\n",
      "        [ 0.0344, -0.0164, -0.0375,  ...,  0.0621, -0.1159,  0.0331]],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#         print(\"when all fails, remember you didn't flatten the input. Bitch\")\n",
    "        self.block_length = 10;\n",
    "        self.state_vector_length = 3; # state_vector = (Px, Py, Pz)\n",
    "        self.control_input_length = 3; # control_input = (Fx, Fy, Fz)\n",
    "        self.visible_features = self.block_length * (self.state_vector_length + self.control_input_length)\n",
    "        self.output_hidden = 100; # Noh\n",
    "        self.latent_features = 50; # Nl\n",
    "        self.tru_units = 50; # Nlh\n",
    "        '''\n",
    "        TRU unit : TRU = {h_lp, h_lc} and l_b_prev\n",
    "        * assuming flattened-out input vectors of size (feature*time_block_length)\n",
    "        \n",
    "        '''\n",
    "        self.h_lp = nn.Linear(self.visible_features, self.output_hidden, bias = False);\n",
    "        self.h_lc = nn.Linear(self.visible_features, self.output_hidden, bias = False);\n",
    "        self.l_b_prev = torch.rand(self.output_hidden);\n",
    "        \n",
    "        '''\n",
    "        Rest of network aka Conditional Dynamic Responses section \n",
    "        CDR = {h_l, h_c, h_f}\n",
    "        '''\n",
    "        self.h_c =  nn.Linear(self.visible_features, self.output_hidden, bias = False);\n",
    "        self.h_f = nn.Linear(self.control_input_length * self.block_length, self.output_hidden, bias = False);\n",
    "        self.h_l = nn.Linear(self.latent_features, self.output_hidden, bias = False);\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        '''\n",
    "        So, since pytorch is in truth a little bitch, Imma go on and assume that\n",
    "        the input variable x is a tuple of (v_b, u_b_next) <- and now I am confused cause\n",
    "        u_b_next is supposed to be the output of  the MPC and that thingy is NOT trained\n",
    "        only online. So, new idea, let's try to isolate the previous parts of the network, \n",
    "        in which case the input is v_b\n",
    "        '''\n",
    "        s = F.Sigmoid()\n",
    "        \n",
    "        '''\n",
    "        TRU pass \n",
    "        h_lc : Wc * v_b\n",
    "        h_lp : Wf * v_b_prev\n",
    "        '''\n",
    "        x = s(self.h_lc(x));\n",
    "        temp = s(self.h_lp(self.l_b_prev));\n",
    "        x = x * temp;\n",
    "        x = x + self.l_b_prev;\n",
    "        x = s(x);\n",
    "        self.l_b_prev = x;\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
